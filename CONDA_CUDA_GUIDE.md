# Conda CUDA å®‰è£…å¿«é€Ÿå‚è€ƒ

**åœ¨ Conda ç¯å¢ƒä¸­å®‰è£…å’Œç®¡ç† CUDA çš„å®Œæ•´æŒ‡å—**

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ä¸€é”®å®‰è£…ï¼ˆæ¨èï¼‰

```bash
# åˆ›å»ºç¯å¢ƒ + CUDA + PyTorch ä¸€æ­¥å®Œæˆ
conda create -n kava python=3.10 \
    cudatoolkit=11.8 \
    pytorch torchvision torchaudio pytorch-cuda=11.8 \
    -c pytorch -c nvidia -y

conda activate kava

# å®‰è£…é¡¹ç›®ä¾èµ–
pip install -r requirements.txt
pip install peft wandb bitsandbytes

# é…ç½®ç¯å¢ƒå˜é‡
export CUDA_HOME=$CONDA_PREFIX
export CUDA_PATH=$CONDA_PREFIX
cd $CONDA_PREFIX && ln -s lib lib64

# éªŒè¯
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}')"
```

---

## ğŸ“¦ è¯¦ç»†å®‰è£…æ­¥éª¤

### Step 1: æŸ¥æ‰¾å¯ç”¨çš„ CUDA ç‰ˆæœ¬

```bash
# æœç´¢ cudatoolkit
conda search cudatoolkit -c nvidia

# å¸¸è§ç‰ˆæœ¬
# - cudatoolkit=11.3
# - cudatoolkit=11.7
# - cudatoolkit=11.8
# - cudatoolkit=12.1
```

### Step 2: åˆ›å»ºç¯å¢ƒå¹¶å®‰è£… CUDA

```bash
# æ–¹æ³• 1: åˆ›å»ºæ—¶å®‰è£…
conda create -n kava python=3.10 cudatoolkit=11.8 -c nvidia -y

# æ–¹æ³• 2: åœ¨ç°æœ‰ç¯å¢ƒä¸­å®‰è£…
conda create -n kava python=3.10 -y
conda activate kava
conda install cudatoolkit=11.8 -c nvidia
```

### Step 3: å®‰è£… PyTorch

```bash
# ç¡®ä¿åŒ¹é… CUDA ç‰ˆæœ¬
# CUDA 11.8
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia

# CUDA 12.1
conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia

# æˆ–ä½¿ç”¨ pipï¼ˆå¤‡é€‰ï¼‰
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### Step 4: é…ç½®ç¯å¢ƒå˜é‡

```bash
# æŸ¥æ‰¾ Conda ç¯å¢ƒè·¯å¾„
conda env list
# è¾“å‡º: kava  /home/username/.conda/envs/kava

# è®¾ç½®ä¸´æ—¶å˜é‡ï¼ˆå½“å‰ä¼šè¯ï¼‰
export CUDA_HOME=$CONDA_PREFIX
export CUDA_PATH=$CONDA_PREFIX
export PATH=$CONDA_PREFIX/bin:$PATH
export LD_LIBRARY_PATH=$CONDA_PREFIX/lib:$LD_LIBRARY_PATH

# åˆ›å»º lib64 é“¾æ¥
cd $CONDA_PREFIX
ln -s lib lib64
```

### Step 5: æ°¸ä¹…é…ç½®ï¼ˆè‡ªåŠ¨æ¿€æ´»ï¼‰

```bash
# åˆ›å»ºæ¿€æ´»è„šæœ¬
conda activate kava
mkdir -p $CONDA_PREFIX/etc/conda/activate.d
mkdir -p $CONDA_PREFIX/etc/conda/deactivate.d

# æ¿€æ´»æ—¶è®¾ç½®å˜é‡
cat > $CONDA_PREFIX/etc/conda/activate.d/env_vars.sh << 'EOF'
#!/bin/bash
export CUDA_HOME=$CONDA_PREFIX
export CUDA_PATH=$CONDA_PREFIX
export PATH=$CONDA_PREFIX/bin:$PATH
export LD_LIBRARY_PATH=$CONDA_PREFIX/lib:$LD_LIBRARY_PATH
export LD_LIBRARY_PATH=$CONDA_PREFIX/lib64:$LD_LIBRARY_PATH
EOF

# åœç”¨æ—¶æ¸…é™¤å˜é‡
cat > $CONDA_PREFIX/etc/conda/deactivate.d/env_vars.sh << 'EOF'
#!/bin/bash
unset CUDA_HOME
unset CUDA_PATH
EOF

# èµ‹äºˆæ‰§è¡Œæƒé™
chmod +x $CONDA_PREFIX/etc/conda/activate.d/env_vars.sh
chmod +x $CONDA_PREFIX/etc/conda/deactivate.d/env_vars.sh

# æµ‹è¯•
conda deactivate
conda activate kava
echo $CUDA_HOME  # åº”æ˜¾ç¤º Conda ç¯å¢ƒè·¯å¾„
```

---

## âœ… éªŒè¯å®‰è£…

### åŸºæœ¬éªŒè¯

```bash
# æ¿€æ´»ç¯å¢ƒ
conda activate kava

# æ£€æŸ¥ Python
python --version

# æ£€æŸ¥ CUDA
nvcc -V
which nvcc

# æ£€æŸ¥ç¯å¢ƒå˜é‡
echo "CUDA_HOME: $CUDA_HOME"
echo "CUDA_PATH: $CUDA_PATH"
echo "LD_LIBRARY_PATH: $LD_LIBRARY_PATH"

# æ£€æŸ¥åº“æ–‡ä»¶
ls $CONDA_PREFIX/lib/libcudart*
ls $CONDA_PREFIX/lib/libcublas*

# æ£€æŸ¥ lib64 é“¾æ¥
ls -la $CONDA_PREFIX | grep lib64
```

### PyTorch éªŒè¯

```bash
# å®Œæ•´éªŒè¯è„šæœ¬
python << 'EOF'
import torch
import sys

print("=" * 60)
print("PyTorch CUDA Verification")
print("=" * 60)
print(f"Python: {sys.version}")
print(f"PyTorch: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")
print(f"CUDA version: {torch.version.cuda}")
print(f"cuDNN version: {torch.backends.cudnn.version()}")
print(f"GPU count: {torch.cuda.device_count()}")

if torch.cuda.is_available():
    print(f"GPU 0: {torch.cuda.get_device_name(0)}")
    print(f"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
    
    # æµ‹è¯•å¼ é‡è¿ç®—
    x = torch.randn(1000, 1000).cuda()
    y = torch.randn(1000, 1000).cuda()
    z = torch.matmul(x, y)
    print("âœ“ GPU tensor operation successful")
else:
    print("âœ— CUDA not available!")
    
print("=" * 60)
EOF
```

### ç¼–è¯‘æµ‹è¯•ï¼ˆå¯é€‰ï¼‰

```bash
# æµ‹è¯• JIT ç¼–è¯‘
python << 'EOF'
import torch
from torch.utils.cpp_extension import load_inline

# ç®€å•çš„ CUDA kernel
cuda_source = """
__global__ void add_kernel(float *a, float *b, float *c, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) c[i] = a[i] + b[i];
}
"""

cpp_source = """
torch::Tensor add(torch::Tensor a, torch::Tensor b) {
    auto c = torch::zeros_like(a);
    int n = a.numel();
    add_kernel<<<(n+255)/256, 256>>>(
        a.data_ptr<float>(), 
        b.data_ptr<float>(), 
        c.data_ptr<float>(), 
        n
    );
    return c;
}
"""

try:
    module = load_inline(
        name='test_cuda',
        cpp_sources=[cpp_source],
        cuda_sources=[cuda_source],
        functions=['add'],
        verbose=True
    )
    print("âœ“ CUDA JIT compilation successful")
except Exception as e:
    print(f"âœ— CUDA JIT compilation failed: {e}")
EOF
```

---

## ğŸ”§ å¸¸è§é—®é¢˜ä¿®å¤

### é—®é¢˜ 1: nvcc æ‰¾ä¸åˆ°

```bash
# æ£€æŸ¥
which nvcc

# å¦‚æœæ²¡æœ‰è¾“å‡º
export PATH=$CONDA_PREFIX/bin:$PATH
which nvcc  # åº”è¯¥æ‰¾åˆ°äº†

# æ°¸ä¹…ä¿®å¤
echo 'export PATH=$CONDA_PREFIX/bin:$PATH' >> $CONDA_PREFIX/etc/conda/activate.d/env_vars.sh
```

### é—®é¢˜ 2: åº“æ–‡ä»¶æ‰¾ä¸åˆ°

```bash
# ç—‡çŠ¶: libcudart.so.11.8: cannot open shared object file

# æ£€æŸ¥åº“æ–‡ä»¶
ls $CONDA_PREFIX/lib/libcudart*

# å¦‚æœå­˜åœ¨ä½†æ‰¾ä¸åˆ°
export LD_LIBRARY_PATH=$CONDA_PREFIX/lib:$LD_LIBRARY_PATH

# åˆ›å»º lib64 é“¾æ¥
cd $CONDA_PREFIX
ln -s lib lib64

# éªŒè¯
ldd $(python -c "import torch; print(torch.__file__)") | grep cuda
```

### é—®é¢˜ 3: CUDA_HOME æœªè®¾ç½®

```bash
# ä¸´æ—¶è®¾ç½®
export CUDA_HOME=$CONDA_PREFIX
export CUDA_PATH=$CONDA_PREFIX

# éªŒè¯
echo $CUDA_HOME
ls $CUDA_HOME/bin/nvcc

# æ°¸ä¹…è®¾ç½®ï¼ˆè§ Step 5ï¼‰
```

### é—®é¢˜ 4: DeepSpeed ç¼–è¯‘å¤±è´¥

```bash
# æ¸…é™¤ç¼“å­˜
rm -rf ~/.cache/torch_extensions/*
rm -rf /tmp/torch_extensions/*

# è®¾ç½®å®Œæ•´ç¯å¢ƒ
export CUDA_HOME=$CONDA_PREFIX
export CUDA_PATH=$CONDA_PREFIX
cd $CONDA_PREFIX && ln -s lib lib64

# é‡æ–°å®‰è£… DeepSpeed
pip uninstall deepspeed -y
pip install deepspeed --no-cache-dir

# æµ‹è¯•
python -c "import deepspeed; print(deepspeed.__version__)"
```

### é—®é¢˜ 5: ç‰ˆæœ¬å†²çª

```bash
# æ£€æŸ¥ CUDA ç‰ˆæœ¬
nvcc -V  # Conda ç‰ˆæœ¬
nvidia-smi  # é©±åŠ¨ç‰ˆæœ¬

# PyTorch æœŸæœ›çš„ CUDA ç‰ˆæœ¬
python -c "import torch; print(torch.version.cuda)"

# å¦‚æœä¸åŒ¹é…ï¼Œé‡æ–°å®‰è£…
conda remove cudatoolkit pytorch -y
conda install cudatoolkit=11.8 -c nvidia
conda install pytorch pytorch-cuda=11.8 -c pytorch -c nvidia
```

---

## ğŸ¯ æœ€ä½³å®è·µ

### 1. ç¯å¢ƒéš”ç¦»

```bash
# ä¸ºä¸åŒé¡¹ç›®åˆ›å»ºç‹¬ç«‹ç¯å¢ƒ
conda create -n kava-cuda11.8 python=3.10 cudatoolkit=11.8
conda create -n kava-cuda12.1 python=3.10 cudatoolkit=12.1

# å¿«é€Ÿåˆ‡æ¢
conda activate kava-cuda11.8
conda activate kava-cuda12.1
```

### 2. è‡ªåŠ¨åŒ–è„šæœ¬

```bash
# åˆ›å»º setup.sh
cat > setup_kava_env.sh << 'EOF'
#!/bin/bash
set -e

ENV_NAME="kava"
CUDA_VERSION="11.8"
PYTHON_VERSION="3.10"

echo "Creating environment: $ENV_NAME"
conda create -n $ENV_NAME python=$PYTHON_VERSION cudatoolkit=$CUDA_VERSION -c nvidia -y

conda activate $ENV_NAME

echo "Installing PyTorch..."
conda install pytorch torchvision torchaudio pytorch-cuda=$CUDA_VERSION -c pytorch -c nvidia -y

echo "Installing dependencies..."
pip install -r requirements.txt
pip install peft wandb bitsandbytes

echo "Configuring environment variables..."
mkdir -p $CONDA_PREFIX/etc/conda/activate.d
cat > $CONDA_PREFIX/etc/conda/activate.d/env_vars.sh << 'INNER_EOF'
#!/bin/bash
export CUDA_HOME=$CONDA_PREFIX
export CUDA_PATH=$CONDA_PREFIX
export PATH=$CONDA_PREFIX/bin:$PATH
export LD_LIBRARY_PATH=$CONDA_PREFIX/lib:$LD_LIBRARY_PATH
INNER_EOF
chmod +x $CONDA_PREFIX/etc/conda/activate.d/env_vars.sh

echo "Creating lib64 link..."
cd $CONDA_PREFIX && ln -sf lib lib64

echo "Verifying installation..."
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}')"

echo "âœ“ Environment setup complete!"
echo "Activate with: conda activate $ENV_NAME"
EOF

chmod +x setup_kava_env.sh
./setup_kava_env.sh
```

### 3. å¤‡ä»½å’Œè¿ç§»

```bash
# å¯¼å‡ºç¯å¢ƒ
conda activate kava
conda env export > kava_environment.yml

# åœ¨æ–°æœºå™¨ä¸Šé‡å»º
conda env create -f kava_environment.yml

# æˆ–ä½¿ç”¨ requirements
pip freeze > requirements_full.txt
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| CUDA æ¥æº | å®‰è£…æ—¶é—´ | ç£ç›˜å ç”¨ | çµæ´»æ€§ | ç¼–è¯‘é€Ÿåº¦ |
|----------|---------|---------|--------|---------|
| ç³»ç»Ÿ CUDA | - | å…±äº« | â˜…â˜…â˜…â˜†â˜† | â˜…â˜…â˜…â˜…â˜… |
| Conda CUDA | ~5 åˆ†é’Ÿ | ~3GB/ç¯å¢ƒ | â˜…â˜…â˜…â˜…â˜… | â˜…â˜…â˜…â˜…â˜† |
| Docker | ~10 åˆ†é’Ÿ | ~10GB | â˜…â˜…â˜…â˜…â˜† | â˜…â˜…â˜…â˜…â˜† |

---

## ğŸ”— èµ„æºé“¾æ¥

- **Conda CUDA Packages**: https://anaconda.org/nvidia/cudatoolkit
- **PyTorch Installation**: https://pytorch.org/get-started/locally/
- **CUDA Toolkit Docs**: https://docs.nvidia.com/cuda/

---

## ğŸ’¡ æç¤º

1. âœ… **é¦–é€‰ Conda CUDA**: é€‚åˆä¸ªäººå¼€å‘ï¼Œéš”ç¦»æ€§å¥½
2. âœ… **ç³»ç»Ÿ CUDA ç”¨äº HPC**: é›†ç¾¤ç¯å¢ƒé€šå¸¸å·²é…ç½®
3. âœ… **æ°¸ä¹…é…ç½®ç¯å¢ƒå˜é‡**: é¿å…æ¯æ¬¡æ‰‹åŠ¨è®¾ç½®
4. âœ… **åˆ›å»º lib64 é“¾æ¥**: è§£å†³å¤§éƒ¨åˆ†é“¾æ¥é—®é¢˜
5. âœ… **å®šæœŸæ›´æ–°**: `conda update cudatoolkit pytorch`
6. âš ï¸ **é©±åŠ¨å…¼å®¹æ€§**: ç¡®ä¿ NVIDIA é©±åŠ¨ç‰ˆæœ¬ >= CUDA ç‰ˆæœ¬
7. âš ï¸ **ç£ç›˜ç©ºé—´**: æ¯ä¸ªç¯å¢ƒçº¦ 3-5GB

---

**å¿«é€Ÿè·å–å¸®åŠ©**
```bash
# Conda å¸®åŠ©
conda info
conda list

# CUDA ä¿¡æ¯
nvcc --version
nvidia-smi

# PyTorch ä¿¡æ¯
python -c "import torch; print(torch.__version__); print(torch.version.cuda)"
```
