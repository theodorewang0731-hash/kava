# ğŸ”§ ä¿®å¤ "Network is unreachable" é—®é¢˜

## ğŸ“‹ é—®é¢˜è¯Šæ–­

**ç—‡çŠ¶**ï¼š
- æ‰€æœ‰ä»»åŠ¡å¿«é€Ÿå¤±è´¥ï¼ˆå‡ ç§’å†…ï¼‰
- `squeue` æ˜¾ç¤º 0 ä¸ªè¿è¡Œä¸­ä»»åŠ¡
- æ—¥å¿—é”™è¯¯ï¼š`[Errno 101] Network is unreachable`
- transformers å°è¯•ä» HuggingFace Hub ä¸‹è½½æ¨¡å‹ä½†å¤±è´¥

**æ ¹æœ¬åŸå› **ï¼š
1. âŒ é…ç½®æ–‡ä»¶ä½¿ç”¨ HF repo IDï¼ˆå¦‚ `meta-llama/Llama-3.2-1B-Instruct`ï¼‰
2. âŒ transformers å°è¯•è”ç½‘è·å–å…ƒæ•°æ®
3. âŒ è®¡ç®—èŠ‚ç‚¹æ— å¤–ç½‘è®¿é—®
4. âŒ æœ¬åœ°ç¼“å­˜å¸ƒå±€ä¸ç¬¦åˆ transformers é¢„æœŸ

---

## âœ… è§£å†³æ–¹æ¡ˆï¼ˆå·²è‡ªåŠ¨ä¿®å¤ï¼‰

### ä¿®æ”¹ 1ï¼šé…ç½®æ–‡ä»¶ä½¿ç”¨æœ¬åœ°è·¯å¾„

**ä¿®æ”¹å‰**ï¼ˆä½¿ç”¨ HF repo IDï¼‰ï¼š
```yaml
model:
  name: "meta-llama/Llama-3.2-1B-Instruct"
```

**ä¿®æ”¹å**ï¼ˆä½¿ç”¨æœ¬åœ°è·¯å¾„ï¼‰ï¼š
```yaml
model:
  name: "/home/share/models/Llama-3.2-1B-Instruct"  # âœ… æœ¬åœ°è·¯å¾„
```

**å·²ä¿®æ”¹çš„æ–‡ä»¶**ï¼š
- âœ… `configs/llama1b_aug.yaml`
- âœ… `configs/llama1b_aug_nl.yaml`
- âœ… `configs/llama3b_aug.yaml`
- âœ… `configs/qwen05b_aug.yaml`

### ä¿®æ”¹ 2ï¼šSLURM è„šæœ¬å¼ºåˆ¶ç¦»çº¿æ¨¡å¼

åœ¨ `submit_multi_seed.slurm` ä¸­æ·»åŠ ï¼š
```bash
# å¼ºåˆ¶ç¦»çº¿æ¨¡å¼ - é¿å…ç½‘ç»œè®¿é—®
export HUGGINGFACE_HUB_OFFLINE=1
export TRANSFORMERS_OFFLINE=1
export HF_HUB_OFFLINE=1
```

**ä¼˜ç‚¹**ï¼š
- âœ… é¿å…ä»»ä½•ç½‘ç»œè®¿é—®å°è¯•
- âœ… åŠ è½½é€Ÿåº¦æ›´å¿«ï¼ˆç›´æ¥è¯»å–æœ¬åœ°æ–‡ä»¶ï¼‰
- âœ… ä¸ä¾èµ–ç¼“å­˜å¸ƒå±€
- âœ… é”™è¯¯ä¿¡æ¯æ›´æ˜ç¡®ï¼ˆç«‹å³å¤±è´¥è€Œéé•¿æ—¶é—´é‡è¯•ï¼‰

---

## ğŸ” éªŒè¯æ­¥éª¤ï¼ˆå»ºè®®å…ˆè¿è¡Œï¼‰

### æ­¥éª¤ 1: è¿è¡Œè¯Šæ–­è„šæœ¬

```bash
cd "/home/rpwang/kava review"
source venv/bin/activate

# è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆä¸ SLURM è„šæœ¬ä¸€è‡´ï¼‰
export HF_HOME=/home/share/models
export TRANSFORMERS_CACHE=/home/share/models
export HUGGINGFACE_HUB_OFFLINE=1
export TRANSFORMERS_OFFLINE=1

# è¿è¡Œè¯Šæ–­
python quick_model_test.py
```

**é¢„æœŸè¾“å‡º**ï¼š
```
âœ… æ¨èæ–¹æ¡ˆ: åœ¨é…ç½®æ–‡ä»¶ä¸­ä½¿ç”¨æœ¬åœ°è·¯å¾„

ä¿®æ”¹ configs/*.yaml ä¸­çš„ model.name ä¸º:
  - llama1b: /home/share/models/Llama-3.2-1B-Instruct
  - llama3b: /home/share/models/Llama-3.2-3B-Instruct
  - qwen05b: /home/share/models/Qwen2.5-0.5B-Instruct

è¿™æ ·å¯ä»¥:
  âœ“ é¿å…ç½‘ç»œè®¿é—®
  âœ“ åŠ è½½é€Ÿåº¦æ›´å¿«
  âœ“ ä¸ä¾èµ–ç¼“å­˜å¸ƒå±€
```

### æ­¥éª¤ 2: å•ä»»åŠ¡æµ‹è¯•ï¼ˆæ¨èï¼‰

åœ¨é‡æ–°æäº¤å…¨éƒ¨ä»»åŠ¡å‰ï¼Œå…ˆæµ‹è¯•ä¸€ä¸ªä»»åŠ¡ï¼š

```bash
# æµ‹è¯•æœ€å°çš„æ¨¡å‹ï¼ˆQwen 0.5Bï¼‰
sbatch --export=CONFIG=qwen05b_aug --array=0 submit_multi_seed.slurm
```

**æ£€æŸ¥æ—¥å¿—**ï¼š
```bash
# ç­‰å¾… 1-2 åˆ†é’Ÿåæ£€æŸ¥
tail -f outputs/logs/kava_qwen05b_aug_*.out
tail -f outputs/logs/kava_qwen05b_aug_*.err
```

**æˆåŠŸæ ‡å¿—**ï¼š
- âœ… æ—¥å¿—æ˜¾ç¤º "Loading model from /home/share/models/..."
- âœ… æ—  "Network is unreachable" é”™è¯¯
- âœ… æ—  "Cannot connect to huggingface.co" é”™è¯¯
- âœ… è®­ç»ƒå¼€å§‹ï¼ˆæ˜¾ç¤º epoch 0, step 0 ç­‰ï¼‰

**å¤±è´¥æ ‡å¿—**ï¼š
- âŒ ä»æœ‰ç½‘ç»œé”™è¯¯ â†’ æ£€æŸ¥ç¯å¢ƒå˜é‡æ˜¯å¦æ­£ç¡®è®¾ç½®
- âŒ "FileNotFoundError" â†’ æ£€æŸ¥å…±äº«åº“è·¯å¾„å’Œæ–‡ä»¶å®Œæ•´æ€§
- âŒ "ImportError" â†’ æ£€æŸ¥ venv æ˜¯å¦æ­£ç¡®æ¿€æ´»

---

## ğŸš€ é‡æ–°æäº¤æ‰€æœ‰ä»»åŠ¡

### æ¸…ç†æ—§æ—¥å¿—ï¼ˆå¯é€‰ï¼‰

```bash
cd "/home/rpwang/kava review"

# å¤‡ä»½æ—§æ—¥å¿—
mkdir -p outputs/logs_backup_$(date +%Y%m%d_%H%M%S)
mv outputs/logs/*.out outputs/logs/*.err outputs/logs_backup_* 2>/dev/null || true

# æˆ–ç›´æ¥åˆ é™¤
rm -f outputs/logs/kava_*.out outputs/logs/kava_*.err
```

### æäº¤æ‰€æœ‰ä»»åŠ¡

```bash
cd "/home/rpwang/kava review"
bash submit_all_jobs.sh
```

**é¢„æœŸè¾“å‡º**ï¼š
```
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
KAVA è®­ç»ƒä»»åŠ¡æ‰¹é‡æäº¤
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

[1/3] éªŒè¯ HPC å…±äº«æ¨¡å‹åº“...
âœ“ Llama-3.2-1B-Instruct å·²æ‰¾åˆ°
âœ“ Llama-3.2-3B-Instruct å·²æ‰¾åˆ°
âœ“ Qwen2.5-0.5B-Instruct å·²æ‰¾åˆ°

[2/3] æäº¤è®­ç»ƒä»»åŠ¡...
æäº¤é…ç½®: llama1b_aug
  ä»»åŠ¡ ID: 20110 (3 ä¸ªå­ä»»åŠ¡: ç§å­ 42, 123, 456)
æäº¤é…ç½®: llama1b_aug_nl
  ä»»åŠ¡ ID: 20111 (3 ä¸ªå­ä»»åŠ¡: ç§å­ 42, 123, 456)
æäº¤é…ç½®: llama3b_aug
  ä»»åŠ¡ ID: 20112 (3 ä¸ªå­ä»»åŠ¡: ç§å­ 42, 123, 456)
æäº¤é…ç½®: qwen05b_aug
  ä»»åŠ¡ ID: 20113 (3 ä¸ªå­ä»»åŠ¡: ç§å­ 42, 123, 456)

æ€»è®¡: 4 ä¸ªä¸»ä»»åŠ¡ï¼Œ12 ä¸ªå­ä»»åŠ¡

[3/3] ç”Ÿæˆè¾…åŠ©è„šæœ¬...
âœ“ monitor_jobs.sh
âœ“ collect_results.sh
```

---

## ğŸ“Š ç›‘æ§ä»»åŠ¡

### è‡ªåŠ¨åˆ·æ–°ç›‘æ§ï¼ˆæ¨èï¼‰

```bash
bash monitor_jobs.sh --auto
```

æ¯ 30 ç§’è‡ªåŠ¨æ›´æ–°ï¼Œæ˜¾ç¤ºï¼š
- ä»»åŠ¡çŠ¶æ€ç»Ÿè®¡
- è¿›åº¦ç™¾åˆ†æ¯”
- æœ€æ–°æ—¥å¿—ç‰‡æ®µ
- GPU ä½¿ç”¨æƒ…å†µ

### æ‰‹åŠ¨æ£€æŸ¥

```bash
# æŸ¥çœ‹é˜Ÿåˆ—
squeue --me

# æŸ¥çœ‹ä»»åŠ¡å†å²
sacct -j 20110,20111,20112,20113 --format=JobID,JobName,State,ExitCode,Start,Elapsed

# æŸ¥çœ‹æœ€æ–°æ—¥å¿—
tail -f outputs/logs/kava_*.out

# æŸ¥çœ‹é”™è¯¯æ—¥å¿—
tail -f outputs/logs/kava_*.err
```

---

## ğŸ› å¸¸è§é—®é¢˜

### Q1: ä»ç„¶å‡ºç° "Network is unreachable"

**æ£€æŸ¥**ï¼š
```bash
# 1. æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å·²æ›´æ–°
grep "name:" configs/*.yaml

# åº”è¯¥çœ‹åˆ°æœ¬åœ°è·¯å¾„ï¼š
# configs/llama1b_aug.yaml:  name: "/home/share/models/Llama-3.2-1B-Instruct"
# configs/qwen05b_aug.yaml:  name: "/home/share/models/Qwen2.5-0.5B-Instruct"

# 2. æ£€æŸ¥ SLURM è„šæœ¬ç¯å¢ƒå˜é‡
grep "OFFLINE" submit_multi_seed.slurm

# åº”è¯¥çœ‹åˆ°ï¼š
# export HUGGINGFACE_HUB_OFFLINE=1
# export TRANSFORMERS_OFFLINE=1
```

### Q2: "FileNotFoundError: config.json not found"

**åŸå› **ï¼šå…±äº«æ¨¡å‹åº“ä¸­æ¨¡å‹æ–‡ä»¶ä¸å®Œæ•´

**æ£€æŸ¥**ï¼š
```bash
ls -lh /home/share/models/Llama-3.2-1B-Instruct/
ls -lh /home/share/models/Qwen2.5-0.5B-Instruct/

# å¿…éœ€æ–‡ä»¶ï¼š
# - config.json
# - tokenizer.json æˆ– tokenizer_config.json
# - *.safetensors æˆ– *.bin (æ¨¡å‹æƒé‡)
```

**è§£å†³**ï¼šè”ç³» HPC ç®¡ç†å‘˜è¡¥å……å®Œæ•´æ¨¡å‹æ–‡ä»¶

### Q3: æ•°æ®é›†ä¸‹è½½å¤±è´¥

**ç—‡çŠ¶**ï¼š`datasets` åº“å°è¯•ä¸‹è½½ GSM8K æ•°æ®é›†

**è§£å†³**ï¼šæ•°æ®é›†å¯ä»¥è”ç½‘ä¸‹è½½ï¼ˆåœ¨ç™»å½•èŠ‚ç‚¹é¢„ä¸‹è½½ï¼‰ï¼š
```bash
# åœ¨ç™»å½•èŠ‚ç‚¹è¿è¡Œï¼ˆæœ‰ç½‘ç»œï¼‰
cd "/home/rpwang/kava review"
source venv/bin/activate

python -c "
from datasets import load_dataset
# é¢„ä¸‹è½½æ•°æ®é›†åˆ°ä¸ªäººç¼“å­˜
dataset = load_dataset('whynlp/gsm8k-aug')
print('âœ“ GSM8K-AUG æ•°æ®é›†å·²ç¼“å­˜')
"
```

---

## ğŸ“ˆ é¢„æœŸç»“æœ

**æ—¶é—´çº¿**ï¼š
- 0-5 åˆ†é’Ÿï¼šä»»åŠ¡è¿›å…¥ PENDING çŠ¶æ€
- 5-30 åˆ†é’Ÿï¼šä»»åŠ¡å¼€å§‹ RUNNINGï¼Œæ¨¡å‹åŠ è½½å®Œæˆ
- æ¯ä¸ª epochï¼š1-4 å°æ—¶ï¼ˆå–å†³äºæ¨¡å‹å¤§å°ï¼‰
- æ€»è®­ç»ƒæ—¶é—´ï¼š12-36 å°æ—¶ï¼ˆQwen æœ€å¿«ï¼ŒLlama-3B æœ€æ…¢ï¼‰

**æˆåŠŸæŒ‡æ ‡**ï¼ˆæ—¥å¿—ä¸­åº”è¯¥çœ‹åˆ°ï¼‰ï¼š
```
âœ“ Loading model from /home/share/models/...
âœ“ Model loaded successfully
âœ“ Training started
âœ“ Epoch 0 | Step 0 | Loss: ...
âœ“ Validation EM: ... | F1: ...
```

**å¤±è´¥æŒ‡æ ‡**ï¼ˆä¸åº”è¯¥çœ‹åˆ°ï¼‰ï¼š
```
âœ— Network is unreachable
âœ— Cannot connect to huggingface.co
âœ— Repository not found
âœ— 401/403 Client Error
```

---

## ğŸ“ éœ€è¦å¸®åŠ©ï¼Ÿ

å¦‚æœé—®é¢˜ä»æœªè§£å†³ï¼Œè¯·æä¾›ï¼š
1. `sacct` è¾“å‡º
2. æœ€æ–°çš„ `.out` å’Œ `.err` æ—¥å¿—æ–‡ä»¶å†…å®¹
3. `quick_model_test.py` çš„è¾“å‡º

---

## âœ¨ ä¿®å¤æ€»ç»“

| é—®é¢˜ | ä¿®å¤ | æ–‡ä»¶ |
|------|------|------|
| ä½¿ç”¨ HF repo ID | æ”¹ä¸ºæœ¬åœ°è·¯å¾„ | `configs/*.yaml` |
| å°è¯•è”ç½‘è®¿é—® | å¼ºåˆ¶ç¦»çº¿æ¨¡å¼ | `submit_multi_seed.slurm` |
| ç¼ºå°‘è¯Šæ–­å·¥å…· | æ·»åŠ éªŒè¯è„šæœ¬ | `quick_model_test.py` |

**æ ¸å¿ƒæ”¹å˜**ï¼š
```yaml
# æ”¹å‰
model:
  name: "meta-llama/Llama-3.2-1B-Instruct"

# æ”¹å  
model:
  name: "/home/share/models/Llama-3.2-1B-Instruct"
```

```bash
# æ–°å¢ç¯å¢ƒå˜é‡
export HUGGINGFACE_HUB_OFFLINE=1
export TRANSFORMERS_OFFLINE=1
```

è¿™ä¸¤ä¸ªæ”¹åŠ¨ç¡®ä¿ï¼š
âœ… transformers ç›´æ¥ä»æœ¬åœ°åŠ è½½  
âœ… ä¸å°è¯•ä»»ä½•ç½‘ç»œè®¿é—®  
âœ… å¿«é€Ÿå¤±è´¥ï¼ˆå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼‰  
âœ… ä¸ HPC ç¯å¢ƒå®Œå…¨å…¼å®¹
