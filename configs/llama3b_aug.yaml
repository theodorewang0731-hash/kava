# LLaMA3.2-3B-Instruct + GSM8k-AUG
# Strictly following Table 6 in the paper

model:
  name: "/home/share/models/Llama-3.2-3B-Instruct"  # HPC 共享库本地路径
  type: "llama"
  
lora:
  r: 128  # Paper Table 6: LoRA rank = 128
  alpha: 32  # Paper Table 6: LoRA α = 32
  dropout: 0.1
  target_modules: ["q_proj", "k_proj", "v_proj", "o_proj"]

latent:
  num_tokens: 24
  num_iterations: 3

dataset:
  name: "whynlp/gsm8k-aug"
  train_size: 385620
  val_size: 500
  test_size: 1319
  cot_type: "equation"

loss:
  alpha1_codi: 20.0  # Higher α₁ for 3B model
  alpha2_kv: 2.0     # Higher α₂ for 3B model
  kv_loss_type: "smooth_l1"
  layerwise_std: false
  use_projection: true

rkv:
  lambda: 0.1

training:
  learning_rate: 2.0e-4  # Paper Table 6: LLaMA-3B = 2e-4
  lr_scheduler: "cosine"
  optimizer: "adamw"
  batch_size: 128
  weight_decay: 0.1
  gradient_clipping: 2.0
  epochs: 5  # Paper Table 6: LLaMA-3B epochs = 5
  warmup_ratio: 0.05
  save_steps: 1000
  eval_steps: 500
  logging_steps: 50

evaluation:
  datasets: ["gsm8k", "gsm8k-hard", "svamp"]
  temperature: 0.0
  top_p: 1.0
  max_new_tokens: 256

system:
  mixed_precision: "bf16"
  gradient_accumulation_steps: 2  # May need more for 3B
  num_workers: 4
  seed: 42
