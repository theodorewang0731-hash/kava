# HPC æ¨¡å‹å’Œæ•°æ®é›†ä¸‹è½½æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

HPC é›†ç¾¤çš„**è®¡ç®—èŠ‚ç‚¹é€šå¸¸æ²¡æœ‰ç½‘ç»œè®¿é—®**ï¼Œä½†**ç™»å½•èŠ‚ç‚¹æœ‰ç½‘ç»œ**ã€‚å› æ­¤éœ€è¦ï¼š
1. åœ¨ç™»å½•èŠ‚ç‚¹ä¸‹è½½æ¨¡å‹å’Œæ•°æ®é›†
2. ä¸‹è½½åˆ°ç”¨æˆ·ç›®å½•æˆ–å…±äº«å­˜å‚¨
3. è®¡ç®—èŠ‚ç‚¹é€šè¿‡æœ¬åœ°è·¯å¾„æˆ–ç¼“å­˜è®¿é—®

## ğŸš€ æ–¹æ³•ä¸€ï¼šä½¿ç”¨ Python è„šæœ¬ï¼ˆæ¨èï¼‰

### 1. å®‰è£…ä¾èµ–

```bash
# åœ¨ç™»å½•èŠ‚ç‚¹
pip install huggingface_hub
```

### 2. ç™»å½• HuggingFaceï¼ˆå¦‚æœéœ€è¦ï¼‰

```bash
# LLaMA æ¨¡å‹éœ€è¦æˆæƒï¼Œå…ˆåœ¨ https://huggingface.co/meta-llama ç”³è¯·
huggingface-cli login
# è¾“å…¥ä½ çš„ HuggingFace token
```

### 3. ä¸‹è½½æ¨¡å‹å’Œæ•°æ®é›†

#### é€‰é¡¹ Aï¼šå…¨éƒ¨ä¸‹è½½
```bash
# ç›´è¿ï¼ˆå›½å¤–æˆ–æœ‰ä»£ç†ï¼‰
python download_from_hf.py

# ä½¿ç”¨é•œåƒï¼ˆå›½å†…æ¨èï¼‰
HF_ENDPOINT=https://hf-mirror.com python download_from_hf.py
```

#### é€‰é¡¹ Bï¼šåªä¸‹è½½æ¨¡å‹
```bash
# ç›´è¿
python download_from_hf.py --models-only

# ä½¿ç”¨é•œåƒ
HF_ENDPOINT=https://hf-mirror.com python download_from_hf.py --models-only
```

#### é€‰é¡¹ Cï¼šåªä¸‹è½½æ•°æ®é›†
```bash
# ç›´è¿
python download_from_hf.py --datasets-only

# ä½¿ç”¨é•œåƒ
HF_ENDPOINT=https://hf-mirror.com python download_from_hf.py --datasets-only
```

### 4. ä¸‹è½½å†…å®¹

**æ¨¡å‹** (ä¸‹è½½åˆ° `./models/`):
- `Llama-3.2-1B-Instruct` (~2.5 GB)
- `Llama-3.2-3B-Instruct` (~6 GB)
- `Qwen2.5-0.5B-Instruct` (~1 GB)

**æ•°æ®é›†** (ä¸‹è½½åˆ° `./datasets/`):
- `gsm8k-aug` (~385K æ ·æœ¬ï¼Œequation-only CoT)
- `gsm8k-aug-nl` (~385K æ ·æœ¬ï¼Œnatural language CoT)
- `gsm8k` (~7.5K è®­ç»ƒ + 1.3K æµ‹è¯•æ ·æœ¬)

## ğŸ”§ æ–¹æ³•äºŒï¼šä½¿ç”¨ Shell è„šæœ¬

### ä¸‹è½½æ¨¡å‹
```bash
# ç›´è¿
bash download_models_only.sh

# ä½¿ç”¨é•œåƒ
HF_ENDPOINT=https://hf-mirror.com bash download_models_only.sh
```

### ä¸‹è½½æ•°æ®é›†
```bash
# ç›´è¿
bash download_datasets_only.sh

# ä½¿ç”¨é•œåƒ
HF_ENDPOINT=https://hf-mirror.com bash download_datasets_only.sh
```

## ğŸ“¦ æ–¹æ³•ä¸‰ï¼šæ‰‹åŠ¨ä½¿ç”¨ huggingface-cli

### ä¸‹è½½æ¨¡å‹
```bash
# ä¸‹è½½ LLaMA-1B
huggingface-cli download meta-llama/Llama-3.2-1B-Instruct \
    --local-dir ./models/Llama-3.2-1B-Instruct \
    --local-dir-use-symlinks False

# ä¸‹è½½ LLaMA-3B
huggingface-cli download meta-llama/Llama-3.2-3B-Instruct \
    --local-dir ./models/Llama-3.2-3B-Instruct \
    --local-dir-use-symlinks False

# ä¸‹è½½ Qwen-0.5B
huggingface-cli download Qwen/Qwen2.5-0.5B-Instruct \
    --local-dir ./models/Qwen2.5-0.5B-Instruct \
    --local-dir-use-symlinks False
```

### ä¸‹è½½æ•°æ®é›†
```bash
# ä¸‹è½½ gsm8k-aug
huggingface-cli download whynlp/gsm8k-aug \
    --repo-type dataset \
    --local-dir ./datasets/gsm8k-aug \
    --local-dir-use-symlinks False

# ä¸‹è½½ gsm8k-aug-nl
huggingface-cli download whynlp/gsm8k-aug-nl \
    --repo-type dataset \
    --local-dir ./datasets/gsm8k-aug-nl \
    --local-dir-use-symlinks False

# ä¸‹è½½ gsm8k
huggingface-cli download gsm8k \
    --repo-type dataset \
    --local-dir ./datasets/gsm8k \
    --local-dir-use-symlinks False
```

### ä½¿ç”¨é•œåƒåŠ é€Ÿ
```bash
# è®¾ç½®ç¯å¢ƒå˜é‡åå†è¿è¡Œä¸Šè¿°å‘½ä»¤
export HF_ENDPOINT=https://hf-mirror.com
```

## ğŸ” æ–¹æ³•å››ï¼šæ£€æŸ¥ HPC å…±äº«å­˜å‚¨

HPC å¯èƒ½å·²ç»æä¾›äº†å…±äº«æ¨¡å‹/æ•°æ®é›†ï¼š

```bash
# è¿è¡Œæ£€æŸ¥è„šæœ¬
bash check_hpc_datasets.sh

# æ‰‹åŠ¨æœç´¢
find /home/share -name "*llama*" -o -name "*qwen*" -o -name "*gsm8k*" 2>/dev/null
```

å¦‚æœæ‰¾åˆ°äº†å…±äº«èµ„æºï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ï¼Œæ— éœ€ä¸‹è½½ï¼

## ğŸ“ æ›´æ–°é…ç½®æ–‡ä»¶

ä¸‹è½½å®Œæˆåï¼Œæ›´æ–°é…ç½®æ–‡ä»¶ä¸­çš„è·¯å¾„ï¼š

### å¦‚æœä¸‹è½½åˆ°æœ¬åœ°ç›®å½•
```yaml
# configs/llama1b_aug.yaml
model:
  name: "./models/Llama-3.2-1B-Instruct"  # ç›¸å¯¹è·¯å¾„
  # æˆ–ç»å¯¹è·¯å¾„: "/home/rpwang/kava review/models/Llama-3.2-1B-Instruct"

dataset:
  name: "./datasets/gsm8k-aug"
```

### å¦‚æœä½¿ç”¨ HPC å…±äº«å­˜å‚¨
```yaml
# configs/llama1b_aug.yaml
model:
  name: "/home/share/models/Llama-3.2-1B-Instruct"  # HPC å…±äº«è·¯å¾„

dataset:
  name: "/home/share/datasets/gsm8k-aug"
```

### å¦‚æœä½¿ç”¨ HuggingFace ç¼“å­˜
```yaml
# configs/llama1b_aug.yaml
model:
  name: "meta-llama/Llama-3.2-1B-Instruct"  # ä¿æŒ repo_id
  # ä»£ç ä¼šè‡ªåŠ¨ä» ~/.cache/huggingface/ åŠ è½½

dataset:
  name: "whynlp/gsm8k-aug"
```

## âš ï¸ å¸¸è§é—®é¢˜

### 1. LLaMA æ¨¡å‹ 403 é”™è¯¯
```
ERROR: Access denied (403)
```
**è§£å†³æ–¹æ³•**:
- è®¿é—® https://huggingface.co/meta-llama/Llama-3.2-1B-Instruct
- ç‚¹å‡» "Request Access" ç”³è¯·æƒé™
- ç­‰å¾…æ‰¹å‡†ï¼ˆé€šå¸¸å‡ åˆ†é’Ÿåˆ°å‡ å°æ—¶ï¼‰
- è¿è¡Œ `huggingface-cli login` ç™»å½•

### 2. ä¸‹è½½é€Ÿåº¦æ…¢
```
Downloading: 0%|          | 0.00/2.5G [00:00<?, ?B/s]
```
**è§£å†³æ–¹æ³•**:
- ä½¿ç”¨é•œåƒ: `HF_ENDPOINT=https://hf-mirror.com`
- ä½¿ç”¨ä»£ç†: `export https_proxy=http://proxy:port`
- æ–­ç‚¹ç»­ä¼ : è„šæœ¬æ”¯æŒ `resume_download=True`

### 3. ç£ç›˜ç©ºé—´ä¸è¶³
```
ERROR: No space left on device
```
**è§£å†³æ–¹æ³•**:
```bash
# æ£€æŸ¥ç£ç›˜ä½¿ç”¨
df -h

# æ¸…ç† HuggingFace ç¼“å­˜
rm -rf ~/.cache/huggingface/hub/*

# ä½¿ç”¨å…¶ä»–ç›®å½•
export HF_HOME=/path/to/large/disk/.cache/huggingface
```

### 4. è®¡ç®—èŠ‚ç‚¹æ— æ³•è®¿é—®
```
ERROR: Network is unreachable
```
**è§£å†³æ–¹æ³•**:
- ç¡®ä¿åœ¨**ç™»å½•èŠ‚ç‚¹**ä¸‹è½½ï¼Œä¸æ˜¯è®¡ç®—èŠ‚ç‚¹
- æ£€æŸ¥ä¸‹è½½è·¯å¾„æ˜¯å¦å¯è¢«è®¡ç®—èŠ‚ç‚¹è®¿é—®
- ä½¿ç”¨ç»å¯¹è·¯å¾„æˆ–è®¾ç½® `local_files_only=True`

## ğŸ“Š ä¸‹è½½æ£€æŸ¥æ¸…å•

ä¸‹è½½å®Œæˆåï¼ŒéªŒè¯æ–‡ä»¶å®Œæ•´æ€§ï¼š

```bash
# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
ls -lh models/Llama-3.2-1B-Instruct/
# åº”è¯¥åŒ…å«:
# - config.json
# - tokenizer.json
# - model-*.safetensors æˆ– pytorch_model.bin

# æ£€æŸ¥æ•°æ®é›†æ–‡ä»¶
ls -lh datasets/gsm8k-aug/
# åº”è¯¥åŒ…å«:
# - dataset_info.json æˆ– README.md
# - train.parquet æˆ– data/ ç›®å½•

# éªŒè¯å¯åŠ è½½
python -c "
from transformers import AutoTokenizer
tokenizer = AutoTokenizer.from_pretrained('./models/Llama-3.2-1B-Instruct', local_files_only=True)
print('âœ“ æ¨¡å‹å¯åŠ è½½')
"

python -c "
from datasets import load_from_disk
dataset = load_from_disk('./datasets/gsm8k-aug')
print('âœ“ æ•°æ®é›†å¯åŠ è½½')
print(f'æ ·æœ¬æ•°: {len(dataset)}')
"
```

## ğŸš€ ä¸‹ä¸€æ­¥

ä¸‹è½½å¹¶éªŒè¯å®Œæˆåï¼š

```bash
# 1. æµ‹è¯•å•ä¸ªè®­ç»ƒä»»åŠ¡
sbatch --export=CONFIG=qwen05b_aug --array=0 submit_multi_seed.slurm

# 2. æäº¤å…¨éƒ¨è®­ç»ƒä»»åŠ¡
bash submit_all_jobs.sh

# 3. ç›‘æ§ä»»åŠ¡çŠ¶æ€
bash monitor_jobs.sh --auto
```

## ğŸ“š å‚è€ƒèµ„æ–™

- [HuggingFace Hub æ–‡æ¡£](https://huggingface.co/docs/huggingface_hub)
- [HF-Mirror é•œåƒç«™](https://hf-mirror.com/)
- [datasets åº“æ–‡æ¡£](https://huggingface.co/docs/datasets)
